{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LLM Take-home assignment round\n",
    "Programmatically solve for these questions. Try to answer as many questions as possible. Try to complete in 48 hours. Some of these may require exploration, so do try.\n",
    "1. Use a pre-trained google/flan-t5-small as the model.\n",
    "2. Verify if the summarization task works.\n",
    "3. Verify if the Q&A task works.\n",
    "4. Verify if English to French translation task works.\n",
    "5. Programmatically print the names of all the model layers and their dimensions.\n",
    "6. Programmatically print the total number of parameters/weights in this model.\n",
    "7. Set the tensor in final layer (decoder.final_layer_norm.weight) to all zeros.\n",
    "8. Verify if the Q&A task works after resettng the weights of the above layer.\n",
    "9. Replace the decoder.final_layer_norm.weight with a layer of smaller dimensions and adjust all the dependent layers to match the dimension\n",
    "10. Reload the original google/flan-t5-small model.\n",
    "11. Train the model for a Q&A task that takes a context as additional input along with the\n",
    "question. You can use SQuAD dataset (h_ps://rajpurkar.github.io/SQuAD-explorer/ ) or the smaller Topioca dataset (h_ps://mcgill-nlp.github.io/topiocqa/) . Choose an appropriate task prefix/trigger word and justify the choice.\n",
    "12. Evaluate the quality of the model\n",
    "Next discussion will be around the solution and geXng deeper into certain algorithms\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a pre-trained google/flan-t5-small as the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, T5ForConditionalGeneration, T5Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "MODEL_PATH = \"google/flan-t5-small\"\n",
    "# tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
    "# model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_PATH)\n",
    "tokenizer = T5Tokenizer.from_pretrained(MODEL_PATH)\n",
    "model = T5ForConditionalGeneration.from_pretrained(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(prompt, sample, padding=\"max_length\"):\n",
    "    #add prompt and input:\n",
    "    inputs = [prompt + sample]\n",
    "    model_inputs = tokenizer(inputs, max_length=512, padding=padding, truncation=True, return_tensors='pt')\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify if the summarization task works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The printing press was a key element in the development of the Renaissance and Protestant Reformation, and was a key factor in the development of the Renaissance.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prompt = \"We have need to summarize large information and you're given that information  \" \\\n",
    "    # \"create a short summary of the information that captures key arguments and important information.\"\n",
    "# prompt = \"Summarize the given text in 'three sentences', focusing on the topic and capture maximum information.\"\n",
    "# prompt = \"summarize: \"\n",
    "prompt = \"summarize the following text : \"\n",
    "# sample = \"\"\"The sergeant brought out a small, withered monkey's paw, and threw it on the table. \"There's magic in what I generally say, so perhaps there may be in this too,\" he said mysteriously. Mrs. White examined it carefully. It was a dry, shrivelled hand with thick, coarse black hairs. Three wrinkles ran across the palm, and down these ran three more, straight from the wrist. Mrs. White had never seen anything so ugly. \"Well, I don't see any good you can get from it,\" she said as she dropped it back into the little brown box.\"\"\"\n",
    "sample = '''The invention of the printing press by Johannes Gutenberg in 1440 marked a revolutionary turning point in human history. This innovation allowed for the mass production of books and other printed materials, which significantly increased literacy rates and the dissemination of knowledge. Before the printing press, information was primarily copied by hand in monasteries, making it a slow and laborious process. Only the wealthy and powerful had access to books and written knowledge. With the arrival of the printing press, information became more accessible to the public, fostering the growth of education, science, and culture. The printing press also played a crucial role in the development of the Renaissance and the Protestant Reformation by enabling the widespread circulation of ideas and religious texts. (Source: Britannica - History of the Printing Press https://www.britannica.com/topic/printing-publishing/The-Gutenberg-press)'''\n",
    "tokenized_sample = tokenize_function(prompt, sample)\n",
    "\n",
    "summarized_ids = model.generate(**tokenized_sample, max_new_tokens=256)\n",
    "summary = tokenizer.decode(summarized_ids[0], skip_special_tokens=True)\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 200, but your input_length is only 198. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=99)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary: The printing press was invented by Johannes Gutenberg in 1440, enabling the mass production of books and other printed materials, which significantly increased literacy rates and the dissemination of knowledge.\n"
     ]
    }
   ],
   "source": [
    "#different approach\n",
    "from transformers import pipeline\n",
    "summarizer = pipeline(\"summarization\", model=MODEL_PATH)\n",
    "\n",
    "prompt = \"summarize the following text : \"\n",
    "# sample = \"\"\"The sergeant brought out a small, withered monkey's paw, and threw it on the table. \"There's magic in what I generally say, so perhaps there may be in this too,\" he said mysteriously. Mrs. White examined it carefully. It was a dry, shrivelled hand with thick, coarse black hairs. Three wrinkles ran across the palm, and down these ran three more, straight from the wrist. Mrs. White had never seen anything so ugly. \"Well, I don't see any good you can get from it,\" she said as she dropped it back into the little brown box.\"\"\"\n",
    "sample = '''The invention of the printing press by Johannes Gutenberg in 1440 marked a revolutionary turning point in human history. This innovation allowed for the mass production of books and other printed materials, which significantly increased literacy rates and the dissemination of knowledge. Before the printing press, information was primarily copied by hand in monasteries, making it a slow and laborious process. Only the wealthy and powerful had access to books and written knowledge. With the arrival of the printing press, information became more accessible to the public, fostering the growth of education, science, and culture. The printing press also played a crucial role in the development of the Renaissance and the Protestant Reformation by enabling the widespread circulation of ideas and religious texts. (Source: Britannica - History of the Printing Press https://www.britannica.com/topic/printing-publishing/The-Gutenberg-press)'''\n",
    "sample_summary = summarizer(prompt+sample)\n",
    "print(\"summary: \" + sample_summary[0]['summary_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify if the Q&A task works.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Carbon monoxide poisoning, gas gangrene, and decompression sickness'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"Answer the following question by reasoning step by step from given context.\"\n",
    "question = \"What does increased oxygen concentrations in the patient's lungs displace?\"\n",
    "context = \"\"\"Hyperbaric (high-pressure) medicine uses special oxygen chambers\n",
    "to increase the partial pressure of O 2 around the patient and, when needed,\n",
    "the medical staff. Carbon monoxide poisoning, gas gangrene, and decompression\n",
    "sickness (the 'bends') are sometimes treated using these devices. Increased\n",
    "O 2 concentration in the lungs helps to displace carbon monoxide from the\n",
    "heme group of hemoglobin. Oxygen gas is poisonous to the anaerobic bacteria\n",
    "that cause gas gangrene, so increasing its partial pressure helps kill them.\n",
    "Decompression sickness occurs in divers who decompress too quickly after\n",
    "a dive, resulting in bubbles of inert gas, mostly nitrogen and helium, forming\n",
    "in their blood. Increasing the pressure of O 2 as soon as possible is part\n",
    "of the treatment.\"\"\"\n",
    "sample = \"question : \" + question + \"context : \" + context\n",
    "\n",
    "tokenized_sample = tokenize_function(prompt, sample)\n",
    "answer_ids = model.generate(**tokenized_sample, max_new_tokens=256)\n",
    "answer = tokenizer.decode(answer_ids[0], skip_special_tokens=True)\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of T5ForQuestionAnswering were not initialized from the model checkpoint at google/flan-t5-small and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.00010763200407382101, 'start': 522, 'end': 562, 'answer': '\\nDecompression sickness occurs in divers'}\n"
     ]
    }
   ],
   "source": [
    "#different approach\n",
    "from transformers import pipeline\n",
    "qa = pipeline(\"question-answering\", model=MODEL_PATH)\n",
    "\n",
    "prompt = \"Answer the following question with reasoning step by step from given context.\"\n",
    "question = \"What does increased oxygen concentrations in the patient's lungs displace?\"\n",
    "context = \"\"\"Hyperbaric (high-pressure) medicine uses special oxygen chambers\n",
    "to increase the partial pressure of O.2 around the patient and, when needed,\n",
    "the medical staff. Carbon monoxide poisoning, gas gangrene, and decompression\n",
    "sickness (the 'bends') are sometimes treated using these devices. Increased\n",
    "O.2 concentration in the lungs helps to displace carbon monoxide from the\n",
    "heme group of hemoglobin. Oxygen gas is poisonous to the anaerobic bacteria\n",
    "that cause gas gangrene, so increasing its partial pressure helps kill them.\n",
    "Decompression sickness occurs in divers who decompress too quickly after\n",
    "a dive, resulting in bubbles of inert gas, mostly nitrogen and helium, forming\n",
    "in their blood. Increasing the pressure of O.2 as soon as possible is part\n",
    "of the treatment.\"\"\"\n",
    "\n",
    "question = prompt + ' ' + question\n",
    "\n",
    "answer = qa(question=question, context=context)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify if English to French translation task works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" quelle sa premier ministre de l'Inde?\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def translate(input_text, src_lang, to_lang):\n",
    "    prompt = f\"Translate {src_lang} to {to_lang}: {input_text}\"\n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
    "    outputs = model.generate(input_ids, max_new_tokens=256)\n",
    "    model_translation = tokenizer.decode(outputs[0])\n",
    "    final_translation = model_translation[5:-4]\n",
    "    return final_translation\n",
    "\n",
    "sample = \"\"\"who is the prime minister of India?\"\"\"\n",
    "\n",
    "translated_text = translate(sample, 'English', 'French')\n",
    "translated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qui est le premier ministre de l'Inde?\n"
     ]
    }
   ],
   "source": [
    "#different approach\n",
    "from transformers import pipeline\n",
    "\n",
    "translator = pipeline('translation_en_to_fr', model=MODEL_PATH)#, src_lang=\"en\", tgt_lang=\"fr\")\n",
    "# text = \"Hello, How is the day?\"\n",
    "text = \"\"\"who is the prime minister of India?\"\"\"\n",
    "\n",
    "\n",
    "translated_text = translator(text)\n",
    "\n",
    "print(translated_text[0]['translation_text'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Programmatically print the names of all the model layers and their dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder Layers:\n",
      "Layer 1:\n",
      "T5Block\n",
      "Nmae: layer.0.SelfAttention.q.weight, Dimension: torch.Size([384, 512])\n",
      "Nmae: layer.0.SelfAttention.k.weight, Dimension: torch.Size([384, 512])\n",
      "Nmae: layer.0.SelfAttention.v.weight, Dimension: torch.Size([384, 512])\n",
      "Nmae: layer.0.SelfAttention.o.weight, Dimension: torch.Size([512, 384])\n",
      "Nmae: layer.0.SelfAttention.relative_attention_bias.weight, Dimension: torch.Size([32, 6])\n",
      "Nmae: layer.0.layer_norm.weight, Dimension: torch.Size([512])\n",
      "Nmae: layer.1.DenseReluDense.wi_0.weight, Dimension: torch.Size([1024, 512])\n",
      "Nmae: layer.1.DenseReluDense.wi_1.weight, Dimension: torch.Size([1024, 512])\n",
      "Nmae: layer.1.DenseReluDense.wo.weight, Dimension: torch.Size([512, 1024])\n",
      "Nmae: layer.1.layer_norm.weight, Dimension: torch.Size([512])\n",
      "Layer 2:\n",
      "T5Block\n",
      "Nmae: layer.0.SelfAttention.q.weight, Dimension: torch.Size([384, 512])\n",
      "Nmae: layer.0.SelfAttention.k.weight, Dimension: torch.Size([384, 512])\n",
      "Nmae: layer.0.SelfAttention.v.weight, Dimension: torch.Size([384, 512])\n",
      "Nmae: layer.0.SelfAttention.o.weight, Dimension: torch.Size([512, 384])\n",
      "Nmae: layer.0.layer_norm.weight, Dimension: torch.Size([512])\n",
      "Nmae: layer.1.DenseReluDense.wi_0.weight, Dimension: torch.Size([1024, 512])\n",
      "Nmae: layer.1.DenseReluDense.wi_1.weight, Dimension: torch.Size([1024, 512])\n",
      "Nmae: layer.1.DenseReluDense.wo.weight, Dimension: torch.Size([512, 1024])\n",
      "Nmae: layer.1.layer_norm.weight, Dimension: torch.Size([512])\n",
      "Layer 3:\n",
      "T5Block\n",
      "Nmae: layer.0.SelfAttention.q.weight, Dimension: torch.Size([384, 512])\n",
      "Nmae: layer.0.SelfAttention.k.weight, Dimension: torch.Size([384, 512])\n",
      "Nmae: layer.0.SelfAttention.v.weight, Dimension: torch.Size([384, 512])\n",
      "Nmae: layer.0.SelfAttention.o.weight, Dimension: torch.Size([512, 384])\n",
      "Nmae: layer.0.layer_norm.weight, Dimension: torch.Size([512])\n",
      "Nmae: layer.1.DenseReluDense.wi_0.weight, Dimension: torch.Size([1024, 512])\n",
      "Nmae: layer.1.DenseReluDense.wi_1.weight, Dimension: torch.Size([1024, 512])\n",
      "Nmae: layer.1.DenseReluDense.wo.weight, Dimension: torch.Size([512, 1024])\n",
      "Nmae: layer.1.layer_norm.weight, Dimension: torch.Size([512])\n",
      "Layer 4:\n",
      "T5Block\n",
      "Nmae: layer.0.SelfAttention.q.weight, Dimension: torch.Size([384, 512])\n",
      "Nmae: layer.0.SelfAttention.k.weight, Dimension: torch.Size([384, 512])\n",
      "Nmae: layer.0.SelfAttention.v.weight, Dimension: torch.Size([384, 512])\n",
      "Nmae: layer.0.SelfAttention.o.weight, Dimension: torch.Size([512, 384])\n",
      "Nmae: layer.0.layer_norm.weight, Dimension: torch.Size([512])\n",
      "Nmae: layer.1.DenseReluDense.wi_0.weight, Dimension: torch.Size([1024, 512])\n",
      "Nmae: layer.1.DenseReluDense.wi_1.weight, Dimension: torch.Size([1024, 512])\n",
      "Nmae: layer.1.DenseReluDense.wo.weight, Dimension: torch.Size([512, 1024])\n",
      "Nmae: layer.1.layer_norm.weight, Dimension: torch.Size([512])\n",
      "Layer 5:\n",
      "T5Block\n",
      "Nmae: layer.0.SelfAttention.q.weight, Dimension: torch.Size([384, 512])\n",
      "Nmae: layer.0.SelfAttention.k.weight, Dimension: torch.Size([384, 512])\n",
      "Nmae: layer.0.SelfAttention.v.weight, Dimension: torch.Size([384, 512])\n",
      "Nmae: layer.0.SelfAttention.o.weight, Dimension: torch.Size([512, 384])\n",
      "Nmae: layer.0.layer_norm.weight, Dimension: torch.Size([512])\n",
      "Nmae: layer.1.DenseReluDense.wi_0.weight, Dimension: torch.Size([1024, 512])\n",
      "Nmae: layer.1.DenseReluDense.wi_1.weight, Dimension: torch.Size([1024, 512])\n",
      "Nmae: layer.1.DenseReluDense.wo.weight, Dimension: torch.Size([512, 1024])\n",
      "Nmae: layer.1.layer_norm.weight, Dimension: torch.Size([512])\n",
      "Layer 6:\n",
      "T5Block\n",
      "Nmae: layer.0.SelfAttention.q.weight, Dimension: torch.Size([384, 512])\n",
      "Nmae: layer.0.SelfAttention.k.weight, Dimension: torch.Size([384, 512])\n",
      "Nmae: layer.0.SelfAttention.v.weight, Dimension: torch.Size([384, 512])\n",
      "Nmae: layer.0.SelfAttention.o.weight, Dimension: torch.Size([512, 384])\n",
      "Nmae: layer.0.layer_norm.weight, Dimension: torch.Size([512])\n",
      "Nmae: layer.1.DenseReluDense.wi_0.weight, Dimension: torch.Size([1024, 512])\n",
      "Nmae: layer.1.DenseReluDense.wi_1.weight, Dimension: torch.Size([1024, 512])\n",
      "Nmae: layer.1.DenseReluDense.wo.weight, Dimension: torch.Size([512, 1024])\n",
      "Nmae: layer.1.layer_norm.weight, Dimension: torch.Size([512])\n",
      "Layer 7:\n",
      "T5Block\n",
      "Nmae: layer.0.SelfAttention.q.weight, Dimension: torch.Size([384, 512])\n",
      "Nmae: layer.0.SelfAttention.k.weight, Dimension: torch.Size([384, 512])\n",
      "Nmae: layer.0.SelfAttention.v.weight, Dimension: torch.Size([384, 512])\n",
      "Nmae: layer.0.SelfAttention.o.weight, Dimension: torch.Size([512, 384])\n",
      "Nmae: layer.0.layer_norm.weight, Dimension: torch.Size([512])\n",
      "Nmae: layer.1.DenseReluDense.wi_0.weight, Dimension: torch.Size([1024, 512])\n",
      "Nmae: layer.1.DenseReluDense.wi_1.weight, Dimension: torch.Size([1024, 512])\n",
      "Nmae: layer.1.DenseReluDense.wo.weight, Dimension: torch.Size([512, 1024])\n",
      "Nmae: layer.1.layer_norm.weight, Dimension: torch.Size([512])\n",
      "Layer 8:\n",
      "T5Block\n",
      "Nmae: layer.0.SelfAttention.q.weight, Dimension: torch.Size([384, 512])\n",
      "Nmae: layer.0.SelfAttention.k.weight, Dimension: torch.Size([384, 512])\n",
      "Nmae: layer.0.SelfAttention.v.weight, Dimension: torch.Size([384, 512])\n",
      "Nmae: layer.0.SelfAttention.o.weight, Dimension: torch.Size([512, 384])\n",
      "Nmae: layer.0.layer_norm.weight, Dimension: torch.Size([512])\n",
      "Nmae: layer.1.DenseReluDense.wi_0.weight, Dimension: torch.Size([1024, 512])\n",
      "Nmae: layer.1.DenseReluDense.wi_1.weight, Dimension: torch.Size([1024, 512])\n",
      "Nmae: layer.1.DenseReluDense.wo.weight, Dimension: torch.Size([512, 1024])\n",
      "Nmae: layer.1.layer_norm.weight, Dimension: torch.Size([512])\n"
     ]
    }
   ],
   "source": [
    "model = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-small\")\n",
    "\n",
    "encoder = model.encoder\n",
    "decoder = model.decoder\n",
    "\n",
    "print(\"Encoder Layers:\")\n",
    "for i, layer in enumerate(encoder.block):\n",
    "    print(f\"Layer {i+1}:\")\n",
    "    print(f\"{type(layer).__name__}\")\n",
    "    for name, param in layer.named_parameters():\n",
    "        print(f\"Name: {name}, Dimension: {param.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder Layers:\n",
      "Layer 1:\n",
      "T5Block\n",
      "Name: layer.0.SelfAttention.q.weight, Dimension: torch.Size([384, 512])\n",
      "Name: layer.0.SelfAttention.k.weight, Dimension: torch.Size([384, 512])\n",
      "Name: layer.0.SelfAttention.v.weight, Dimension: torch.Size([384, 512])\n",
      "Name: layer.0.SelfAttention.o.weight, Dimension: torch.Size([512, 384])\n",
      "Name: layer.0.SelfAttention.relative_attention_bias.weight, Dimension: torch.Size([32, 6])\n",
      "Name: layer.0.layer_norm.weight, Dimension: torch.Size([512])\n",
      "Name: layer.1.EncDecAttention.q.weight, Dimension: torch.Size([384, 512])\n",
      "Name: layer.1.EncDecAttention.k.weight, Dimension: torch.Size([384, 512])\n",
      "Name: layer.1.EncDecAttention.v.weight, Dimension: torch.Size([384, 512])\n",
      "Name: layer.1.EncDecAttention.o.weight, Dimension: torch.Size([512, 384])\n",
      "Name: layer.1.layer_norm.weight, Dimension: torch.Size([512])\n",
      "Name: layer.2.DenseReluDense.wi_0.weight, Dimension: torch.Size([1024, 512])\n",
      "Name: layer.2.DenseReluDense.wi_1.weight, Dimension: torch.Size([1024, 512])\n",
      "Name: layer.2.DenseReluDense.wo.weight, Dimension: torch.Size([512, 1024])\n",
      "Name: layer.2.layer_norm.weight, Dimension: torch.Size([512])\n",
      "Layer 2:\n",
      "T5Block\n",
      "Name: layer.0.SelfAttention.q.weight, Dimension: torch.Size([384, 512])\n",
      "Name: layer.0.SelfAttention.k.weight, Dimension: torch.Size([384, 512])\n",
      "Name: layer.0.SelfAttention.v.weight, Dimension: torch.Size([384, 512])\n",
      "Name: layer.0.SelfAttention.o.weight, Dimension: torch.Size([512, 384])\n",
      "Name: layer.0.layer_norm.weight, Dimension: torch.Size([512])\n",
      "Name: layer.1.EncDecAttention.q.weight, Dimension: torch.Size([384, 512])\n",
      "Name: layer.1.EncDecAttention.k.weight, Dimension: torch.Size([384, 512])\n",
      "Name: layer.1.EncDecAttention.v.weight, Dimension: torch.Size([384, 512])\n",
      "Name: layer.1.EncDecAttention.o.weight, Dimension: torch.Size([512, 384])\n",
      "Name: layer.1.layer_norm.weight, Dimension: torch.Size([512])\n",
      "Name: layer.2.DenseReluDense.wi_0.weight, Dimension: torch.Size([1024, 512])\n",
      "Name: layer.2.DenseReluDense.wi_1.weight, Dimension: torch.Size([1024, 512])\n",
      "Name: layer.2.DenseReluDense.wo.weight, Dimension: torch.Size([512, 1024])\n",
      "Name: layer.2.layer_norm.weight, Dimension: torch.Size([512])\n",
      "Layer 3:\n",
      "T5Block\n",
      "Name: layer.0.SelfAttention.q.weight, Dimension: torch.Size([384, 512])\n",
      "Name: layer.0.SelfAttention.k.weight, Dimension: torch.Size([384, 512])\n",
      "Name: layer.0.SelfAttention.v.weight, Dimension: torch.Size([384, 512])\n",
      "Name: layer.0.SelfAttention.o.weight, Dimension: torch.Size([512, 384])\n",
      "Name: layer.0.layer_norm.weight, Dimension: torch.Size([512])\n",
      "Name: layer.1.EncDecAttention.q.weight, Dimension: torch.Size([384, 512])\n",
      "Name: layer.1.EncDecAttention.k.weight, Dimension: torch.Size([384, 512])\n",
      "Name: layer.1.EncDecAttention.v.weight, Dimension: torch.Size([384, 512])\n",
      "Name: layer.1.EncDecAttention.o.weight, Dimension: torch.Size([512, 384])\n",
      "Name: layer.1.layer_norm.weight, Dimension: torch.Size([512])\n",
      "Name: layer.2.DenseReluDense.wi_0.weight, Dimension: torch.Size([1024, 512])\n",
      "Name: layer.2.DenseReluDense.wi_1.weight, Dimension: torch.Size([1024, 512])\n",
      "Name: layer.2.DenseReluDense.wo.weight, Dimension: torch.Size([512, 1024])\n",
      "Name: layer.2.layer_norm.weight, Dimension: torch.Size([512])\n",
      "Layer 4:\n",
      "T5Block\n",
      "Name: layer.0.SelfAttention.q.weight, Dimension: torch.Size([384, 512])\n",
      "Name: layer.0.SelfAttention.k.weight, Dimension: torch.Size([384, 512])\n",
      "Name: layer.0.SelfAttention.v.weight, Dimension: torch.Size([384, 512])\n",
      "Name: layer.0.SelfAttention.o.weight, Dimension: torch.Size([512, 384])\n",
      "Name: layer.0.layer_norm.weight, Dimension: torch.Size([512])\n",
      "Name: layer.1.EncDecAttention.q.weight, Dimension: torch.Size([384, 512])\n",
      "Name: layer.1.EncDecAttention.k.weight, Dimension: torch.Size([384, 512])\n",
      "Name: layer.1.EncDecAttention.v.weight, Dimension: torch.Size([384, 512])\n",
      "Name: layer.1.EncDecAttention.o.weight, Dimension: torch.Size([512, 384])\n",
      "Name: layer.1.layer_norm.weight, Dimension: torch.Size([512])\n",
      "Name: layer.2.DenseReluDense.wi_0.weight, Dimension: torch.Size([1024, 512])\n",
      "Name: layer.2.DenseReluDense.wi_1.weight, Dimension: torch.Size([1024, 512])\n",
      "Name: layer.2.DenseReluDense.wo.weight, Dimension: torch.Size([512, 1024])\n",
      "Name: layer.2.layer_norm.weight, Dimension: torch.Size([512])\n",
      "Layer 5:\n",
      "T5Block\n",
      "Name: layer.0.SelfAttention.q.weight, Dimension: torch.Size([384, 512])\n",
      "Name: layer.0.SelfAttention.k.weight, Dimension: torch.Size([384, 512])\n",
      "Name: layer.0.SelfAttention.v.weight, Dimension: torch.Size([384, 512])\n",
      "Name: layer.0.SelfAttention.o.weight, Dimension: torch.Size([512, 384])\n",
      "Name: layer.0.layer_norm.weight, Dimension: torch.Size([512])\n",
      "Name: layer.1.EncDecAttention.q.weight, Dimension: torch.Size([384, 512])\n",
      "Name: layer.1.EncDecAttention.k.weight, Dimension: torch.Size([384, 512])\n",
      "Name: layer.1.EncDecAttention.v.weight, Dimension: torch.Size([384, 512])\n",
      "Name: layer.1.EncDecAttention.o.weight, Dimension: torch.Size([512, 384])\n",
      "Name: layer.1.layer_norm.weight, Dimension: torch.Size([512])\n",
      "Name: layer.2.DenseReluDense.wi_0.weight, Dimension: torch.Size([1024, 512])\n",
      "Name: layer.2.DenseReluDense.wi_1.weight, Dimension: torch.Size([1024, 512])\n",
      "Name: layer.2.DenseReluDense.wo.weight, Dimension: torch.Size([512, 1024])\n",
      "Name: layer.2.layer_norm.weight, Dimension: torch.Size([512])\n",
      "Layer 6:\n",
      "T5Block\n",
      "Name: layer.0.SelfAttention.q.weight, Dimension: torch.Size([384, 512])\n",
      "Name: layer.0.SelfAttention.k.weight, Dimension: torch.Size([384, 512])\n",
      "Name: layer.0.SelfAttention.v.weight, Dimension: torch.Size([384, 512])\n",
      "Name: layer.0.SelfAttention.o.weight, Dimension: torch.Size([512, 384])\n",
      "Name: layer.0.layer_norm.weight, Dimension: torch.Size([512])\n",
      "Name: layer.1.EncDecAttention.q.weight, Dimension: torch.Size([384, 512])\n",
      "Name: layer.1.EncDecAttention.k.weight, Dimension: torch.Size([384, 512])\n",
      "Name: layer.1.EncDecAttention.v.weight, Dimension: torch.Size([384, 512])\n",
      "Name: layer.1.EncDecAttention.o.weight, Dimension: torch.Size([512, 384])\n",
      "Name: layer.1.layer_norm.weight, Dimension: torch.Size([512])\n",
      "Name: layer.2.DenseReluDense.wi_0.weight, Dimension: torch.Size([1024, 512])\n",
      "Name: layer.2.DenseReluDense.wi_1.weight, Dimension: torch.Size([1024, 512])\n",
      "Name: layer.2.DenseReluDense.wo.weight, Dimension: torch.Size([512, 1024])\n",
      "Name: layer.2.layer_norm.weight, Dimension: torch.Size([512])\n",
      "Layer 7:\n",
      "T5Block\n",
      "Name: layer.0.SelfAttention.q.weight, Dimension: torch.Size([384, 512])\n",
      "Name: layer.0.SelfAttention.k.weight, Dimension: torch.Size([384, 512])\n",
      "Name: layer.0.SelfAttention.v.weight, Dimension: torch.Size([384, 512])\n",
      "Name: layer.0.SelfAttention.o.weight, Dimension: torch.Size([512, 384])\n",
      "Name: layer.0.layer_norm.weight, Dimension: torch.Size([512])\n",
      "Name: layer.1.EncDecAttention.q.weight, Dimension: torch.Size([384, 512])\n",
      "Name: layer.1.EncDecAttention.k.weight, Dimension: torch.Size([384, 512])\n",
      "Name: layer.1.EncDecAttention.v.weight, Dimension: torch.Size([384, 512])\n",
      "Name: layer.1.EncDecAttention.o.weight, Dimension: torch.Size([512, 384])\n",
      "Name: layer.1.layer_norm.weight, Dimension: torch.Size([512])\n",
      "Name: layer.2.DenseReluDense.wi_0.weight, Dimension: torch.Size([1024, 512])\n",
      "Name: layer.2.DenseReluDense.wi_1.weight, Dimension: torch.Size([1024, 512])\n",
      "Name: layer.2.DenseReluDense.wo.weight, Dimension: torch.Size([512, 1024])\n",
      "Name: layer.2.layer_norm.weight, Dimension: torch.Size([512])\n",
      "Layer 8:\n",
      "T5Block\n",
      "Name: layer.0.SelfAttention.q.weight, Dimension: torch.Size([384, 512])\n",
      "Name: layer.0.SelfAttention.k.weight, Dimension: torch.Size([384, 512])\n",
      "Name: layer.0.SelfAttention.v.weight, Dimension: torch.Size([384, 512])\n",
      "Name: layer.0.SelfAttention.o.weight, Dimension: torch.Size([512, 384])\n",
      "Name: layer.0.layer_norm.weight, Dimension: torch.Size([512])\n",
      "Name: layer.1.EncDecAttention.q.weight, Dimension: torch.Size([384, 512])\n",
      "Name: layer.1.EncDecAttention.k.weight, Dimension: torch.Size([384, 512])\n",
      "Name: layer.1.EncDecAttention.v.weight, Dimension: torch.Size([384, 512])\n",
      "Name: layer.1.EncDecAttention.o.weight, Dimension: torch.Size([512, 384])\n",
      "Name: layer.1.layer_norm.weight, Dimension: torch.Size([512])\n",
      "Name: layer.2.DenseReluDense.wi_0.weight, Dimension: torch.Size([1024, 512])\n",
      "Name: layer.2.DenseReluDense.wi_1.weight, Dimension: torch.Size([1024, 512])\n",
      "Name: layer.2.DenseReluDense.wo.weight, Dimension: torch.Size([512, 1024])\n",
      "Name: layer.2.layer_norm.weight, Dimension: torch.Size([512])\n"
     ]
    }
   ],
   "source": [
    "print(\"Decoder Layers:\")\n",
    "for i, layer in enumerate(decoder.block):\n",
    "  print(f\"Layer {i+1}:\")\n",
    "  print(f\"{type(layer).__name__}\")\n",
    "  for name, param in layer.named_parameters():\n",
    "    print(f\"Name: {name}, Dimension: {param.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Programmatically print the total number of parameters/weights in this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Parameters/Weights in flan-t5-small: 76961152\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "\n",
    "print(f\"Total Parameters/Weights in flan-t5-small: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the tensor in final layer (decoder.final_layer_norm.weight) to all zeros.\n",
    "Verify if the Q&A task works after resettng the weights of the above layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for p in model.decoder.parameters():\n",
    "#     print(p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder = model.decoder\n",
    "decoder_weight = decoder.final_layer_norm.weight\n",
    "\n",
    "decoder_weight.data.fill_(0)\n",
    "model.save_pretrained(\"modified1_flan-t5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = T5ForConditionalGeneration.from_pretrained(\"modified1_flan-t5-small\")\n",
    "\n",
    "prompt = \"Answer the following question by reasoning step by step from given context.\"\n",
    "question = \"What does increased oxygen concentrations in the patient's lungs displace?\"\n",
    "context = \"\"\"Hyperbaric (high-pressure) medicine uses special oxygen chambers\n",
    "to increase the partial pressure of O 2 around the patient and, when needed,\n",
    "the medical staff. Carbon monoxide poisoning, gas gangrene, and decompression\n",
    "sickness (the 'bends') are sometimes treated using these devices. Increased\n",
    "O 2 concentration in the lungs helps to displace carbon monoxide from the\n",
    "heme group of hemoglobin. Oxygen gas is poisonous to the anaerobic bacteria\n",
    "that cause gas gangrene, so increasing its partial pressure helps kill them.\n",
    "Decompression sickness occurs in divers who decompress too quickly after\n",
    "a dive, resulting in bubbles of inert gas, mostly nitrogen and helium, forming\n",
    "in their blood. Increasing the pressure of O 2 as soon as possible is part\n",
    "of the treatment.\"\"\"\n",
    "sample = \"question : \" + question + \"context : \" + context\n",
    "\n",
    "tokenized_sample = tokenize_function(prompt, sample)\n",
    "answer_ids = model1.generate(**tokenized_sample, max_new_tokens=256)\n",
    "answer = tokenizer.decode(answer_ids[0], skip_special_tokens=True)\n",
    "answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#After setting the final_layer_norm.weights to 0's , the output for Q&A is EMPTY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace the decoder.final_layer_norm.weight with a layer of smaller dimensions and adjust all the dependent layers to match the dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = T5ForConditionalGeneration.from_pretrained(MODEL_PATH)\n",
    "model.decoder.final_layer_norm.weight.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "new_dim = 256 #new dimension that is lower than the dimension of final_layer_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decreaing the dimension of the weights of the final_layer_norm\n",
    "final_layer = model.decoder.final_layer_norm\n",
    "final_layer.weight = torch.nn.Parameter(torch.randn(new_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adjusting the weights of the related layers\n",
    "for i, layer in enumerate(model.decoder.block):\n",
    "    for name, param in layer.named_parameters():\n",
    "        if 'layer_norm' in name :\n",
    "            param.data = torch.nn.Parameter(torch.randn(new_dim))\n",
    "        if 'SelfAttention.q' in name :\n",
    "            param.data = torch.nn.Parameter(torch.randn(384, new_dim))\n",
    "        if 'SelfAttention.k' in name :\n",
    "            param.data = torch.nn.Parameter(torch.randn(384, new_dim))\n",
    "        if 'SelfAttention.v' in name :\n",
    "            param.data = torch.nn.Parameter(torch.randn(384, new_dim))\n",
    "        if 'SelfAttention.o' in name :\n",
    "            param.data = torch.nn.Parameter(torch.randn(new_dim, 384))\n",
    "        if 'EncDecAttention.q' in name :\n",
    "            param.data = torch.nn.Parameter(torch.randn(384, new_dim))\n",
    "        if 'EncDecAttention.k' in name :\n",
    "            param.data = torch.nn.Parameter(torch.randn(384, new_dim))\n",
    "        if 'EncDecAttention.v' in name :\n",
    "            param.data = torch.nn.Parameter(torch.randn(384, new_dim))\n",
    "        if 'EncDecAttention.o' in name :\n",
    "            param.data = torch.nn.Parameter(torch.randn(new_dim, 384))\n",
    "        if 'DenseReluDense.wi_0' in name:\n",
    "            param.data = torch.nn.Parameter(torch.randn(1024, new_dim))\n",
    "        if 'DenseReluDense.wi_1' in name:\n",
    "            param.data = torch.nn.Parameter(torch.randn(1024, new_dim))\n",
    "        if 'DenseReluDense.wo' in name:\n",
    "            param.data = torch.nn.Parameter(torch.randn(new_dim, 1024))\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder Layers:\n",
      "Layer 1:\n",
      "T5Block\n",
      "Name: layer.0.SelfAttention.q.weight, Dimension: torch.Size([384, 256])\n",
      "Name: layer.0.SelfAttention.k.weight, Dimension: torch.Size([384, 256])\n",
      "Name: layer.0.SelfAttention.v.weight, Dimension: torch.Size([384, 256])\n",
      "Name: layer.0.SelfAttention.o.weight, Dimension: torch.Size([256, 384])\n",
      "Name: layer.0.SelfAttention.relative_attention_bias.weight, Dimension: torch.Size([32, 6])\n",
      "Name: layer.0.layer_norm.weight, Dimension: torch.Size([256])\n",
      "Name: layer.1.EncDecAttention.q.weight, Dimension: torch.Size([384, 256])\n",
      "Name: layer.1.EncDecAttention.k.weight, Dimension: torch.Size([384, 256])\n",
      "Name: layer.1.EncDecAttention.v.weight, Dimension: torch.Size([384, 256])\n",
      "Name: layer.1.EncDecAttention.o.weight, Dimension: torch.Size([256, 384])\n",
      "Name: layer.1.layer_norm.weight, Dimension: torch.Size([256])\n",
      "Name: layer.2.DenseReluDense.wi_0.weight, Dimension: torch.Size([1024, 256])\n",
      "Name: layer.2.DenseReluDense.wi_1.weight, Dimension: torch.Size([1024, 256])\n",
      "Name: layer.2.DenseReluDense.wo.weight, Dimension: torch.Size([256, 1024])\n",
      "Name: layer.2.layer_norm.weight, Dimension: torch.Size([256])\n",
      "Layer 2:\n",
      "T5Block\n",
      "Name: layer.0.SelfAttention.q.weight, Dimension: torch.Size([384, 256])\n",
      "Name: layer.0.SelfAttention.k.weight, Dimension: torch.Size([384, 256])\n",
      "Name: layer.0.SelfAttention.v.weight, Dimension: torch.Size([384, 256])\n",
      "Name: layer.0.SelfAttention.o.weight, Dimension: torch.Size([256, 384])\n",
      "Name: layer.0.layer_norm.weight, Dimension: torch.Size([256])\n",
      "Name: layer.1.EncDecAttention.q.weight, Dimension: torch.Size([384, 256])\n",
      "Name: layer.1.EncDecAttention.k.weight, Dimension: torch.Size([384, 256])\n",
      "Name: layer.1.EncDecAttention.v.weight, Dimension: torch.Size([384, 256])\n",
      "Name: layer.1.EncDecAttention.o.weight, Dimension: torch.Size([256, 384])\n",
      "Name: layer.1.layer_norm.weight, Dimension: torch.Size([256])\n",
      "Name: layer.2.DenseReluDense.wi_0.weight, Dimension: torch.Size([1024, 256])\n",
      "Name: layer.2.DenseReluDense.wi_1.weight, Dimension: torch.Size([1024, 256])\n",
      "Name: layer.2.DenseReluDense.wo.weight, Dimension: torch.Size([256, 1024])\n",
      "Name: layer.2.layer_norm.weight, Dimension: torch.Size([256])\n",
      "Layer 3:\n",
      "T5Block\n",
      "Name: layer.0.SelfAttention.q.weight, Dimension: torch.Size([384, 256])\n",
      "Name: layer.0.SelfAttention.k.weight, Dimension: torch.Size([384, 256])\n",
      "Name: layer.0.SelfAttention.v.weight, Dimension: torch.Size([384, 256])\n",
      "Name: layer.0.SelfAttention.o.weight, Dimension: torch.Size([256, 384])\n",
      "Name: layer.0.layer_norm.weight, Dimension: torch.Size([256])\n",
      "Name: layer.1.EncDecAttention.q.weight, Dimension: torch.Size([384, 256])\n",
      "Name: layer.1.EncDecAttention.k.weight, Dimension: torch.Size([384, 256])\n",
      "Name: layer.1.EncDecAttention.v.weight, Dimension: torch.Size([384, 256])\n",
      "Name: layer.1.EncDecAttention.o.weight, Dimension: torch.Size([256, 384])\n",
      "Name: layer.1.layer_norm.weight, Dimension: torch.Size([256])\n",
      "Name: layer.2.DenseReluDense.wi_0.weight, Dimension: torch.Size([1024, 256])\n",
      "Name: layer.2.DenseReluDense.wi_1.weight, Dimension: torch.Size([1024, 256])\n",
      "Name: layer.2.DenseReluDense.wo.weight, Dimension: torch.Size([256, 1024])\n",
      "Name: layer.2.layer_norm.weight, Dimension: torch.Size([256])\n",
      "Layer 4:\n",
      "T5Block\n",
      "Name: layer.0.SelfAttention.q.weight, Dimension: torch.Size([384, 256])\n",
      "Name: layer.0.SelfAttention.k.weight, Dimension: torch.Size([384, 256])\n",
      "Name: layer.0.SelfAttention.v.weight, Dimension: torch.Size([384, 256])\n",
      "Name: layer.0.SelfAttention.o.weight, Dimension: torch.Size([256, 384])\n",
      "Name: layer.0.layer_norm.weight, Dimension: torch.Size([256])\n",
      "Name: layer.1.EncDecAttention.q.weight, Dimension: torch.Size([384, 256])\n",
      "Name: layer.1.EncDecAttention.k.weight, Dimension: torch.Size([384, 256])\n",
      "Name: layer.1.EncDecAttention.v.weight, Dimension: torch.Size([384, 256])\n",
      "Name: layer.1.EncDecAttention.o.weight, Dimension: torch.Size([256, 384])\n",
      "Name: layer.1.layer_norm.weight, Dimension: torch.Size([256])\n",
      "Name: layer.2.DenseReluDense.wi_0.weight, Dimension: torch.Size([1024, 256])\n",
      "Name: layer.2.DenseReluDense.wi_1.weight, Dimension: torch.Size([1024, 256])\n",
      "Name: layer.2.DenseReluDense.wo.weight, Dimension: torch.Size([256, 1024])\n",
      "Name: layer.2.layer_norm.weight, Dimension: torch.Size([256])\n",
      "Layer 5:\n",
      "T5Block\n",
      "Name: layer.0.SelfAttention.q.weight, Dimension: torch.Size([384, 256])\n",
      "Name: layer.0.SelfAttention.k.weight, Dimension: torch.Size([384, 256])\n",
      "Name: layer.0.SelfAttention.v.weight, Dimension: torch.Size([384, 256])\n",
      "Name: layer.0.SelfAttention.o.weight, Dimension: torch.Size([256, 384])\n",
      "Name: layer.0.layer_norm.weight, Dimension: torch.Size([256])\n",
      "Name: layer.1.EncDecAttention.q.weight, Dimension: torch.Size([384, 256])\n",
      "Name: layer.1.EncDecAttention.k.weight, Dimension: torch.Size([384, 256])\n",
      "Name: layer.1.EncDecAttention.v.weight, Dimension: torch.Size([384, 256])\n",
      "Name: layer.1.EncDecAttention.o.weight, Dimension: torch.Size([256, 384])\n",
      "Name: layer.1.layer_norm.weight, Dimension: torch.Size([256])\n",
      "Name: layer.2.DenseReluDense.wi_0.weight, Dimension: torch.Size([1024, 256])\n",
      "Name: layer.2.DenseReluDense.wi_1.weight, Dimension: torch.Size([1024, 256])\n",
      "Name: layer.2.DenseReluDense.wo.weight, Dimension: torch.Size([256, 1024])\n",
      "Name: layer.2.layer_norm.weight, Dimension: torch.Size([256])\n",
      "Layer 6:\n",
      "T5Block\n",
      "Name: layer.0.SelfAttention.q.weight, Dimension: torch.Size([384, 256])\n",
      "Name: layer.0.SelfAttention.k.weight, Dimension: torch.Size([384, 256])\n",
      "Name: layer.0.SelfAttention.v.weight, Dimension: torch.Size([384, 256])\n",
      "Name: layer.0.SelfAttention.o.weight, Dimension: torch.Size([256, 384])\n",
      "Name: layer.0.layer_norm.weight, Dimension: torch.Size([256])\n",
      "Name: layer.1.EncDecAttention.q.weight, Dimension: torch.Size([384, 256])\n",
      "Name: layer.1.EncDecAttention.k.weight, Dimension: torch.Size([384, 256])\n",
      "Name: layer.1.EncDecAttention.v.weight, Dimension: torch.Size([384, 256])\n",
      "Name: layer.1.EncDecAttention.o.weight, Dimension: torch.Size([256, 384])\n",
      "Name: layer.1.layer_norm.weight, Dimension: torch.Size([256])\n",
      "Name: layer.2.DenseReluDense.wi_0.weight, Dimension: torch.Size([1024, 256])\n",
      "Name: layer.2.DenseReluDense.wi_1.weight, Dimension: torch.Size([1024, 256])\n",
      "Name: layer.2.DenseReluDense.wo.weight, Dimension: torch.Size([256, 1024])\n",
      "Name: layer.2.layer_norm.weight, Dimension: torch.Size([256])\n",
      "Layer 7:\n",
      "T5Block\n",
      "Name: layer.0.SelfAttention.q.weight, Dimension: torch.Size([384, 256])\n",
      "Name: layer.0.SelfAttention.k.weight, Dimension: torch.Size([384, 256])\n",
      "Name: layer.0.SelfAttention.v.weight, Dimension: torch.Size([384, 256])\n",
      "Name: layer.0.SelfAttention.o.weight, Dimension: torch.Size([256, 384])\n",
      "Name: layer.0.layer_norm.weight, Dimension: torch.Size([256])\n",
      "Name: layer.1.EncDecAttention.q.weight, Dimension: torch.Size([384, 256])\n",
      "Name: layer.1.EncDecAttention.k.weight, Dimension: torch.Size([384, 256])\n",
      "Name: layer.1.EncDecAttention.v.weight, Dimension: torch.Size([384, 256])\n",
      "Name: layer.1.EncDecAttention.o.weight, Dimension: torch.Size([256, 384])\n",
      "Name: layer.1.layer_norm.weight, Dimension: torch.Size([256])\n",
      "Name: layer.2.DenseReluDense.wi_0.weight, Dimension: torch.Size([1024, 256])\n",
      "Name: layer.2.DenseReluDense.wi_1.weight, Dimension: torch.Size([1024, 256])\n",
      "Name: layer.2.DenseReluDense.wo.weight, Dimension: torch.Size([256, 1024])\n",
      "Name: layer.2.layer_norm.weight, Dimension: torch.Size([256])\n",
      "Layer 8:\n",
      "T5Block\n",
      "Name: layer.0.SelfAttention.q.weight, Dimension: torch.Size([384, 256])\n",
      "Name: layer.0.SelfAttention.k.weight, Dimension: torch.Size([384, 256])\n",
      "Name: layer.0.SelfAttention.v.weight, Dimension: torch.Size([384, 256])\n",
      "Name: layer.0.SelfAttention.o.weight, Dimension: torch.Size([256, 384])\n",
      "Name: layer.0.layer_norm.weight, Dimension: torch.Size([256])\n",
      "Name: layer.1.EncDecAttention.q.weight, Dimension: torch.Size([384, 256])\n",
      "Name: layer.1.EncDecAttention.k.weight, Dimension: torch.Size([384, 256])\n",
      "Name: layer.1.EncDecAttention.v.weight, Dimension: torch.Size([384, 256])\n",
      "Name: layer.1.EncDecAttention.o.weight, Dimension: torch.Size([256, 384])\n",
      "Name: layer.1.layer_norm.weight, Dimension: torch.Size([256])\n",
      "Name: layer.2.DenseReluDense.wi_0.weight, Dimension: torch.Size([1024, 256])\n",
      "Name: layer.2.DenseReluDense.wi_1.weight, Dimension: torch.Size([1024, 256])\n",
      "Name: layer.2.DenseReluDense.wo.weight, Dimension: torch.Size([256, 1024])\n",
      "Name: layer.2.layer_norm.weight, Dimension: torch.Size([256])\n"
     ]
    }
   ],
   "source": [
    "# Printing Updated dimensions of the decoder layer\n",
    "print(\"Decoder Layers:\")\n",
    "for i, layer in enumerate(decoder.block):\n",
    "    print(f\"Layer {i+1}:\")\n",
    "    print(f\"{type(layer).__name__}\")\n",
    "    for name, param in layer.named_parameters():\n",
    "        print(f\"Name: {name}, Dimension: {param.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjusting the dimensions of the encoder layer as the self attention from encoder are needed by decoder\n",
    "for i, layer in enumerate(model.encoder.block):\n",
    "    for name, param in layer.named_parameters():\n",
    "        if 'SelfAttention.q' in name :\n",
    "            param.data = torch.nn.Parameter(torch.randn(384, new_dim))\n",
    "        if 'SelfAttention.k' in name :\n",
    "            param.data = torch.nn.Parameter(torch.randn(384, new_dim))\n",
    "        if 'SelfAttention.v' in name :\n",
    "            param.data = torch.nn.Parameter(torch.randn(384, new_dim))\n",
    "        if 'SelfAttention.o' in name :\n",
    "            param.data = torch.nn.Parameter(torch.randn(new_dim, 384))\n",
    "        if 'layer_norm' in name :\n",
    "            param.data = torch.nn.Parameter(torch.randn(new_dim))\n",
    "        if 'DenseReluDense.wi_0' in name:\n",
    "            param.data = torch.nn.Parameter(torch.randn(1024, new_dim))\n",
    "        if 'DenseReluDense.wi_1' in name:\n",
    "            param.data = torch.nn.Parameter(torch.randn(1024, new_dim))\n",
    "        if 'DenseReluDense.wo' in name:\n",
    "            param.data = torch.nn.Parameter(torch.randn(new_dim, 1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder Layers:\n",
      "Layer 1:\n",
      "T5Block\n",
      "Name: layer.0.SelfAttention.q.weight, Dimension: torch.Size([384, 256])\n",
      "Name: layer.0.SelfAttention.k.weight, Dimension: torch.Size([384, 256])\n",
      "Name: layer.0.SelfAttention.v.weight, Dimension: torch.Size([384, 256])\n",
      "Name: layer.0.SelfAttention.o.weight, Dimension: torch.Size([256, 384])\n",
      "Name: layer.0.SelfAttention.relative_attention_bias.weight, Dimension: torch.Size([32, 6])\n",
      "Name: layer.0.layer_norm.weight, Dimension: torch.Size([256])\n",
      "Name: layer.1.DenseReluDense.wi_0.weight, Dimension: torch.Size([1024, 256])\n",
      "Name: layer.1.DenseReluDense.wi_1.weight, Dimension: torch.Size([1024, 256])\n",
      "Name: layer.1.DenseReluDense.wo.weight, Dimension: torch.Size([256, 1024])\n",
      "Name: layer.1.layer_norm.weight, Dimension: torch.Size([256])\n",
      "Layer 2:\n",
      "T5Block\n",
      "Name: layer.0.SelfAttention.q.weight, Dimension: torch.Size([384, 256])\n",
      "Name: layer.0.SelfAttention.k.weight, Dimension: torch.Size([384, 256])\n",
      "Name: layer.0.SelfAttention.v.weight, Dimension: torch.Size([384, 256])\n",
      "Name: layer.0.SelfAttention.o.weight, Dimension: torch.Size([256, 384])\n",
      "Name: layer.0.layer_norm.weight, Dimension: torch.Size([256])\n",
      "Name: layer.1.DenseReluDense.wi_0.weight, Dimension: torch.Size([1024, 256])\n",
      "Name: layer.1.DenseReluDense.wi_1.weight, Dimension: torch.Size([1024, 256])\n",
      "Name: layer.1.DenseReluDense.wo.weight, Dimension: torch.Size([256, 1024])\n",
      "Name: layer.1.layer_norm.weight, Dimension: torch.Size([256])\n",
      "Layer 3:\n",
      "T5Block\n",
      "Name: layer.0.SelfAttention.q.weight, Dimension: torch.Size([384, 256])\n",
      "Name: layer.0.SelfAttention.k.weight, Dimension: torch.Size([384, 256])\n",
      "Name: layer.0.SelfAttention.v.weight, Dimension: torch.Size([384, 256])\n",
      "Name: layer.0.SelfAttention.o.weight, Dimension: torch.Size([256, 384])\n",
      "Name: layer.0.layer_norm.weight, Dimension: torch.Size([256])\n",
      "Name: layer.1.DenseReluDense.wi_0.weight, Dimension: torch.Size([1024, 256])\n",
      "Name: layer.1.DenseReluDense.wi_1.weight, Dimension: torch.Size([1024, 256])\n",
      "Name: layer.1.DenseReluDense.wo.weight, Dimension: torch.Size([256, 1024])\n",
      "Name: layer.1.layer_norm.weight, Dimension: torch.Size([256])\n",
      "Layer 4:\n",
      "T5Block\n",
      "Name: layer.0.SelfAttention.q.weight, Dimension: torch.Size([384, 256])\n",
      "Name: layer.0.SelfAttention.k.weight, Dimension: torch.Size([384, 256])\n",
      "Name: layer.0.SelfAttention.v.weight, Dimension: torch.Size([384, 256])\n",
      "Name: layer.0.SelfAttention.o.weight, Dimension: torch.Size([256, 384])\n",
      "Name: layer.0.layer_norm.weight, Dimension: torch.Size([256])\n",
      "Name: layer.1.DenseReluDense.wi_0.weight, Dimension: torch.Size([1024, 256])\n",
      "Name: layer.1.DenseReluDense.wi_1.weight, Dimension: torch.Size([1024, 256])\n",
      "Name: layer.1.DenseReluDense.wo.weight, Dimension: torch.Size([256, 1024])\n",
      "Name: layer.1.layer_norm.weight, Dimension: torch.Size([256])\n",
      "Layer 5:\n",
      "T5Block\n",
      "Name: layer.0.SelfAttention.q.weight, Dimension: torch.Size([384, 256])\n",
      "Name: layer.0.SelfAttention.k.weight, Dimension: torch.Size([384, 256])\n",
      "Name: layer.0.SelfAttention.v.weight, Dimension: torch.Size([384, 256])\n",
      "Name: layer.0.SelfAttention.o.weight, Dimension: torch.Size([256, 384])\n",
      "Name: layer.0.layer_norm.weight, Dimension: torch.Size([256])\n",
      "Name: layer.1.DenseReluDense.wi_0.weight, Dimension: torch.Size([1024, 256])\n",
      "Name: layer.1.DenseReluDense.wi_1.weight, Dimension: torch.Size([1024, 256])\n",
      "Name: layer.1.DenseReluDense.wo.weight, Dimension: torch.Size([256, 1024])\n",
      "Name: layer.1.layer_norm.weight, Dimension: torch.Size([256])\n",
      "Layer 6:\n",
      "T5Block\n",
      "Name: layer.0.SelfAttention.q.weight, Dimension: torch.Size([384, 256])\n",
      "Name: layer.0.SelfAttention.k.weight, Dimension: torch.Size([384, 256])\n",
      "Name: layer.0.SelfAttention.v.weight, Dimension: torch.Size([384, 256])\n",
      "Name: layer.0.SelfAttention.o.weight, Dimension: torch.Size([256, 384])\n",
      "Name: layer.0.layer_norm.weight, Dimension: torch.Size([256])\n",
      "Name: layer.1.DenseReluDense.wi_0.weight, Dimension: torch.Size([1024, 256])\n",
      "Name: layer.1.DenseReluDense.wi_1.weight, Dimension: torch.Size([1024, 256])\n",
      "Name: layer.1.DenseReluDense.wo.weight, Dimension: torch.Size([256, 1024])\n",
      "Name: layer.1.layer_norm.weight, Dimension: torch.Size([256])\n",
      "Layer 7:\n",
      "T5Block\n",
      "Name: layer.0.SelfAttention.q.weight, Dimension: torch.Size([384, 256])\n",
      "Name: layer.0.SelfAttention.k.weight, Dimension: torch.Size([384, 256])\n",
      "Name: layer.0.SelfAttention.v.weight, Dimension: torch.Size([384, 256])\n",
      "Name: layer.0.SelfAttention.o.weight, Dimension: torch.Size([256, 384])\n",
      "Name: layer.0.layer_norm.weight, Dimension: torch.Size([256])\n",
      "Name: layer.1.DenseReluDense.wi_0.weight, Dimension: torch.Size([1024, 256])\n",
      "Name: layer.1.DenseReluDense.wi_1.weight, Dimension: torch.Size([1024, 256])\n",
      "Name: layer.1.DenseReluDense.wo.weight, Dimension: torch.Size([256, 1024])\n",
      "Name: layer.1.layer_norm.weight, Dimension: torch.Size([256])\n",
      "Layer 8:\n",
      "T5Block\n",
      "Name: layer.0.SelfAttention.q.weight, Dimension: torch.Size([384, 256])\n",
      "Name: layer.0.SelfAttention.k.weight, Dimension: torch.Size([384, 256])\n",
      "Name: layer.0.SelfAttention.v.weight, Dimension: torch.Size([384, 256])\n",
      "Name: layer.0.SelfAttention.o.weight, Dimension: torch.Size([256, 384])\n",
      "Name: layer.0.layer_norm.weight, Dimension: torch.Size([256])\n",
      "Name: layer.1.DenseReluDense.wi_0.weight, Dimension: torch.Size([1024, 256])\n",
      "Name: layer.1.DenseReluDense.wi_1.weight, Dimension: torch.Size([1024, 256])\n",
      "Name: layer.1.DenseReluDense.wo.weight, Dimension: torch.Size([256, 1024])\n",
      "Name: layer.1.layer_norm.weight, Dimension: torch.Size([256])\n"
     ]
    }
   ],
   "source": [
    "#printing the updated weights of the encoder layer\n",
    "print(\"Encoder Layers:\")\n",
    "for i, layer in enumerate(model.encoder.block):\n",
    "    print(f\"Layer {i+1}:\")\n",
    "    print(f\"{type(layer).__name__}\")\n",
    "    for name, param in layer.named_parameters():\n",
    "        print(f\"Name: {name}, Dimension: {param.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"new_dim_256_flan-t5-small\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The task of Finetuning the flan-t5-small model is implemented in separate notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiclaudio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
